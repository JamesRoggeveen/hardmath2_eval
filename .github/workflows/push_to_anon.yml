ame: Build & Push Dataset to GitHub

on:
  push:
    branches:
      - main # This triggers the workflow on push to main in THIS repository

jobs:
  build-and-push:
    permissions:
      contents: write # Grants GITHUB_TOKEN write access to THIS repository
    runs-on: ubuntu-latest
    env:
      GH_TOKEN: ${{ secrets.GH_TOKEN }}    # MUST be a PAT with access to the target repo
      GH_REPO: ${{ secrets.GH_REPO }}      # e.g., 'username/my-dataset-repo'
      GH_DATASET_DIR: gh-repo_checkout     # Changed name to avoid conflict if gh-repo exists at root
      TARGET_BRANCH: main                  # Define target branch for clarity

    steps:
      - name: Checkout source repository
        uses: actions/checkout@v4
        # `fetch-depth: 0` is usually for history-dependent actions,
        # if not needed, remove it for faster checkout.
        with:
          fetch-depth: 0

      - name: Checkout target repository
        uses: actions/checkout@v4
        with:
          repository: ${{ env.GH_REPO }}
          token: ${{ env.GH_TOKEN }} # Use the PAT here
          path: ${{ env.GH_DATASET_DIR }}
          ref: ${{ env.TARGET_BRANCH }} # Explicitly specify the branch to checkout/push to
          # fetch-depth: 0 # Uncomment if you need full history in target repo, else 1 is fine.

      #
      # ADD YOUR BUILD/DATA GENERATION STEPS HERE if needed
      # These steps would operate on the source checkout (current directory)
      #
      # - name: Build my data
      #   run: |
      #     python generate_data.py --output my_output_data/
      #

      - name: Copy/Prepare files for dataset repository
        run: |
          echo "Preparing files for ${{ env.GH_DATASET_DIR }}..."
          TARGET_DIR="${{ env.GH_DATASET_DIR }}"

          # Create directories in target if they don't exist
          mkdir -p "$TARGET_DIR/src"
          mkdir -p "$TARGET_DIR/scripts"

          # Example: Copying files/dirs from source checkout to target checkout
          # Adjust these commands based on what you need to copy
          # Using rsync is often more robust for copying directories
          rsync -av --delete ./requirements.txt "$TARGET_DIR/requirements.txt"
          rsync -av --delete ./setup.py "$TARGET_DIR/setup.py"
          rsync -av --delete ./src/ "$TARGET_DIR/src/"
          rsync -av --delete ./scripts/ "$TARGET_DIR/scripts/"
          rsync -av --delete ./README.md "$TARGET_DIR/README.md"

          # If you generated data, copy it too:
          # rsync -av --delete ./my_output_data/ "$TARGET_DIR/data/"

      - name: Configure Git user for target repository
        working-directory: ${{ env.GH_DATASET_DIR }}
        run: |
          git config user.name "CI Bot"
          git config user.email "ci-bot@users.noreply.github.com"

      - name: Commit & Push changes to target repository
        working-directory: ${{ env.GH_DATASET_DIR }}
        env:
          # Pass the token explicitly for the push command if needed,
          # though git credential helper set up by actions/checkout with token should work.
          GITHUB_TOKEN: ${{ env.GH_TOKEN }}
        run: |
          echo "Checking for changes in $PWD"
          git status # For debugging

          # Add all changes in the target directory.
          # Using `.` is generally safer if you've rsynced everything.
          git add .

          # Check if there are changes staged for commit
          if ! git diff --cached --quiet; then
            echo "Committing changes..."
            git commit -m "Auto-update dataset from source [skip ci]"
            echo "Pushing changes to origin/${{ env.TARGET_BRANCH }}..."
            # Use HEAD to refer to the current commit on the locally checked out branch
            git push origin HEAD:${{ env.TARGET_BRANCH }}
          else
            echo "No changes to commit in ${{ env.GH_DATASET_DIR }}"
          fi